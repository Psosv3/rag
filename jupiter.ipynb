{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67df7895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Serveur_Onexus\\rag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "d:\\Serveur_Onexus\\rag\\rag_utils.py:267: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"Onexia est une solution d'intelligence artificielle développée pour faciliter les interactions vocales et textuelles dans un environnement collaboratif virtuel. Voici une description plus détaillée de ses fonctionnalités et de son architecture, ainsi que des instructions d'utilisation et des perspectives d'évolution.\\n\\n### Architecture et Fonctionnalités\\n\\n- **Frontend** : Le frontend de Onexia inclut un module audio basé sur WebRTC, une interface utilisateur intuitive, et des capacités d'analyse des flux audio en temps réel.\\n- **Backend** : Le backend est construit avec FastAPI et intègre des modules de traitement vocal avancés, tels que la reconnaissance automatique de la parole (ASR), la détection de la parole (VAD), et la synthèse vocale (TTS).\\n- **IA** : Le moteur de réponse de Onexia est alimenté par des modèles de langage avancés comme GPT ou Mistral. Il utilise également le Retrieval-Augmented Generation (RAG) pour fournir des réponses contextualisées et pertinentes.\\n\\n### Processus de Traitement des Données\\n\\nLes données vocales sont transmises du frontend au backend en temps réel. Les enregistrements audio sont traités pour détecter les silences (VAD) et transcrire le texte (ASR). Les réponses générées par l'IA sont ensuite restituées sous forme audio (TTS).\\n\\n### Mode d'Utilisation de Onexia\\n\\n1. **Inscription** : Pour commencer, vous devez compléter les informations sur la page d'inscription ou importer automatiquement votre CV.\\n2. **Accès à l'Application** : Une fois inscrit, vous serez dirigé vers une page où un code vous sera demandé. Un e-mail contenant ce code sera envoyé à votre compte. Utilisez le code reçu pour accéder à l'application.\\n3. **Autorisation des Périphériques Audio** : Autorisez tous les périphériques audio (microphone, haut-parleurs) pour une communication fluide.\\n4. **Discussion avec Onexia** : Discutez avec Onexia normalement. Il est recommandé de poursuivre la conversation pendant 10 minutes pour une évaluation complète.\\n5. **Terminer l'Entretien** : Si vous souhaitez terminer l'entretien, cliquez sur 'Terminer l'entretien'.\\n6. **Consultation des Résultats** : À la fin, cliquez sur 'Voir le résultat' en bas du site. Vous recevrez un e-mail avec votre résultat.\\n\\n### Bonnes Pratiques et Limitations\\n\\n- **Validation Humaine** : L'IA ne remplace pas l'évaluation humaine. Il est recommandé de valider les résultats avec un expert.\\n- **Confidentialité des Données** : Garantir la confidentialité des données vocales et textuelles.\\n- **Optimisation de la Qualité Audio** : Suivre les recommandations pour optimiser la qualité audio et la précision des transcriptions.\\n\\n### Perspectives d'Évolution\\n\\n- **Détection des Émotions Vocales** : Onexia pourrait évoluer pour inclure la détection des émotions vocales, permettant une interaction plus empathique.\\n- **Support Multilingue Complet** : Développement d'un support multilingue complet pour une utilisation plus large et inclusive.\\n\\nEn résumé, Onexia est une solution complète qui combine des technologies avancées de traitement vocal et d'intelligence artificielle pour améliorer les interactions et la collaboration dans des environnements virtuels.\", 'sources': [Document(metadata={'source_id': 0, 'chunk_id': 0}, page_content=\"Onexia - Agent IA interne de [Votre entreprise]\\n1. Présentation générale\\nOnexia est un agent IA développé par Onexus pour vous. Il est conçu pour faciliter les échanges vocaux et textuels, automatiser la prise de notes et la synthèse des conversations, ainsi que pour fournir une assistance personnalisée aux utilisateurs dans un environnement collaboratif virtuel.\\n2. Objectifs et cas d'usage\\n- Faciliter la communication dans les espaces collaboratifs (ex: Onexus workspace)\\n- Automatiser la prise de notes et les synthèses de réunion\\n- Aider à la navigation dans l'espace virtuel\\n- Assister les candidats pendant les entretiens IA\\n3. Architecture et composants\\n- Frontend : module audio (WebRTC), interface utilisateur et analyse des flux audio\"), Document(metadata={'source_id': 0, 'chunk_id': 1}, page_content=\"- Frontend : module audio (WebRTC), interface utilisateur et analyse des flux audio\\n- Backend : FastAPI, modules de traitement vocal (ASR, VAD, TTS)\\n- IA : Moteur de réponse alimenté par GPT/Mistral, support RAG pour des réponses contextualisées\\n4. Données et traitements\\nLes données vocales sont transmises du frontend au backend en temps réel. Les enregistrements audio sont traités pour détecter les silences (VAD) et transcrire le texte (ASR). Les réponses IA sont générées et restituées sous forme audio (TTS).\\n5. Mode d'utilisation de Onexia\\n1) Complétez les informations sur la page d'inscription, ou importez automatiquement le CV.\\n2) Vous arriverez sur une page où un code vous sera demandé. Un e-mail sera envoyé à votre compte et vous utiliserez le code reçu pour accéder à l'application.\"), Document(metadata={'source_id': 0, 'chunk_id': 2}, page_content=\"3) Autorisez tous les périphériques audio (microphone, haut-parleurs).\\n4) Discutez avec Onexia normalement.\\n5) Si vous souhaitez terminer l'entretien, cliquez sur 'Terminer l'entretien'. Il est recommandé de poursuivre la conversation pendant 10 minutes pour une évaluation complète.\\n6) A la fin, cliquez sur 'Voir le résultat' en bas du site. Vous recevrez un e-mail avec votre résultat.\\n6. Bonnes pratiques et limitations\\n- L'IA ne remplace pas l'évaluation humaine : validez les résultats avec un expert.\\n- Garantir la confidentialité des données vocales et textuelles.\\n- Suivre les recommandations pour optimiser la qualité audio et la précision des transcriptions.\\n7. Perspectives d'évolution\\n- Détection des émotions vocales.\\n- Support multilingue complet.\")]}\n",
      "Onexia est une solution d'intelligence artificielle développée pour faciliter les interactions vocales et textuelles dans un environnement collaboratif virtuel. Voici une description plus détaillée de ses fonctionnalités et de son architecture, ainsi que des instructions d'utilisation et des perspectives d'évolution.\n",
      "\n",
      "### Architecture et Fonctionnalités\n",
      "\n",
      "- **Frontend** : Le frontend de Onexia inclut un module audio basé sur WebRTC, une interface utilisateur intuitive, et des capacités d'analyse des flux audio en temps réel.\n",
      "- **Backend** : Le backend est construit avec FastAPI et intègre des modules de traitement vocal avancés, tels que la reconnaissance automatique de la parole (ASR), la détection de la parole (VAD), et la synthèse vocale (TTS).\n",
      "- **IA** : Le moteur de réponse de Onexia est alimenté par des modèles de langage avancés comme GPT ou Mistral. Il utilise également le Retrieval-Augmented Generation (RAG) pour fournir des réponses contextualisées et pertinentes.\n",
      "\n",
      "### Processus de Traitement des Données\n",
      "\n",
      "Les données vocales sont transmises du frontend au backend en temps réel. Les enregistrements audio sont traités pour détecter les silences (VAD) et transcrire le texte (ASR). Les réponses générées par l'IA sont ensuite restituées sous forme audio (TTS).\n",
      "\n",
      "### Mode d'Utilisation de Onexia\n",
      "\n",
      "1. **Inscription** : Pour commencer, vous devez compléter les informations sur la page d'inscription ou importer automatiquement votre CV.\n",
      "2. **Accès à l'Application** : Une fois inscrit, vous serez dirigé vers une page où un code vous sera demandé. Un e-mail contenant ce code sera envoyé à votre compte. Utilisez le code reçu pour accéder à l'application.\n",
      "3. **Autorisation des Périphériques Audio** : Autorisez tous les périphériques audio (microphone, haut-parleurs) pour une communication fluide.\n",
      "4. **Discussion avec Onexia** : Discutez avec Onexia normalement. Il est recommandé de poursuivre la conversation pendant 10 minutes pour une évaluation complète.\n",
      "5. **Terminer l'Entretien** : Si vous souhaitez terminer l'entretien, cliquez sur 'Terminer l'entretien'.\n",
      "6. **Consultation des Résultats** : À la fin, cliquez sur 'Voir le résultat' en bas du site. Vous recevrez un e-mail avec votre résultat.\n",
      "\n",
      "### Bonnes Pratiques et Limitations\n",
      "\n",
      "- **Validation Humaine** : L'IA ne remplace pas l'évaluation humaine. Il est recommandé de valider les résultats avec un expert.\n",
      "- **Confidentialité des Données** : Garantir la confidentialité des données vocales et textuelles.\n",
      "- **Optimisation de la Qualité Audio** : Suivre les recommandations pour optimiser la qualité audio et la précision des transcriptions.\n",
      "\n",
      "### Perspectives d'Évolution\n",
      "\n",
      "- **Détection des Émotions Vocales** : Onexia pourrait évoluer pour inclure la détection des émotions vocales, permettant une interaction plus empathique.\n",
      "- **Support Multilingue Complet** : Développement d'un support multilingue complet pour une utilisation plus large et inclusive.\n",
      "\n",
      "En résumé, Onexia est une solution complète qui combine des technologies avancées de traitement vocal et d'intelligence artificielle pour améliorer les interactions et la collaboration dans des environnements virtuels.\n",
      "[Document(metadata={'source_id': 0, 'chunk_id': 0}, page_content=\"Onexia - Agent IA interne de [Votre entreprise]\\n1. Présentation générale\\nOnexia est un agent IA développé par Onexus pour vous. Il est conçu pour faciliter les échanges vocaux et textuels, automatiser la prise de notes et la synthèse des conversations, ainsi que pour fournir une assistance personnalisée aux utilisateurs dans un environnement collaboratif virtuel.\\n2. Objectifs et cas d'usage\\n- Faciliter la communication dans les espaces collaboratifs (ex: Onexus workspace)\\n- Automatiser la prise de notes et les synthèses de réunion\\n- Aider à la navigation dans l'espace virtuel\\n- Assister les candidats pendant les entretiens IA\\n3. Architecture et composants\\n- Frontend : module audio (WebRTC), interface utilisateur et analyse des flux audio\"), Document(metadata={'source_id': 0, 'chunk_id': 1}, page_content=\"- Frontend : module audio (WebRTC), interface utilisateur et analyse des flux audio\\n- Backend : FastAPI, modules de traitement vocal (ASR, VAD, TTS)\\n- IA : Moteur de réponse alimenté par GPT/Mistral, support RAG pour des réponses contextualisées\\n4. Données et traitements\\nLes données vocales sont transmises du frontend au backend en temps réel. Les enregistrements audio sont traités pour détecter les silences (VAD) et transcrire le texte (ASR). Les réponses IA sont générées et restituées sous forme audio (TTS).\\n5. Mode d'utilisation de Onexia\\n1) Complétez les informations sur la page d'inscription, ou importez automatiquement le CV.\\n2) Vous arriverez sur une page où un code vous sera demandé. Un e-mail sera envoyé à votre compte et vous utiliserez le code reçu pour accéder à l'application.\"), Document(metadata={'source_id': 0, 'chunk_id': 2}, page_content=\"3) Autorisez tous les périphériques audio (microphone, haut-parleurs).\\n4) Discutez avec Onexia normalement.\\n5) Si vous souhaitez terminer l'entretien, cliquez sur 'Terminer l'entretien'. Il est recommandé de poursuivre la conversation pendant 10 minutes pour une évaluation complète.\\n6) A la fin, cliquez sur 'Voir le résultat' en bas du site. Vous recevrez un e-mail avec votre résultat.\\n6. Bonnes pratiques et limitations\\n- L'IA ne remplace pas l'évaluation humaine : validez les résultats avec un expert.\\n- Garantir la confidentialité des données vocales et textuelles.\\n- Suivre les recommandations pour optimiser la qualité audio et la précision des transcriptions.\\n7. Perspectives d'évolution\\n- Détection des émotions vocales.\\n- Support multilingue complet.\")]\n"
     ]
    }
   ],
   "source": [
    "from rag_utils import get_answer, build_index, get_answer\n",
    "from fastapi import HTTPException\n",
    "import os\n",
    "from models import mistral_llm\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Variable globale pour stocker l'index\n",
    "vectordb = None\n",
    "\n",
    "vectordb = build_index(DATA_DIR, HTTPException)\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "resp = get_answer(\"c'est quoi onexia?\",retriever,mistral_llm, chain_type=\"refine\")\n",
    "print(resp)\n",
    "print(resp[\"answer\"])\n",
    "print(resp[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from langchain_mistralai.chat_models import ChatMistralAI\n",
    "\n",
    "mistral_llm = ChatMistralAI(\n",
    "    api_key=\"MMgzK02HosimPpErmKqWrEC1xbGSIAuC\",\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.7,\n",
    ")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65fded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
